
import os
import json
import copy
from jsonschema import validate
import cv2


def remove_empty_lists(dictionary):
    if not isinstance(dictionary, (dict, list)):
        return dictionary
    if isinstance(dictionary, list):
        return [v for v in (remove_empty_lists(v) for v in dictionary) if v or v == 0]
    return {k: v for k, v in ((k, remove_empty_lists(v)) for k, v in dictionary.items()) if v or v == 0}

def validate_output_against_schema(output_location):
    if not output_location or not os.path.exists(output_location):
        print("output_location not found")
        return
    json_schema = None
    json_schema_file = os.path.join(os.path.dirname(__file__), 'common/Extension_Data_Schema.json')
    with open(json_schema_file, "r") as read_file:
        json_schema = json.load(read_file)

    #Read each inference result and compare against the schema
    with open(output_location, "r") as file_:
        for line in file_:
            if line and line != '':
                dictionary = json.loads(line)
                dictionary = remove_empty_lists(dictionary)
                if dictionary.get("inferences"):
                    for inference in dictionary["inferences"]:
                        inference["type"] = inference["type"].lower()
                validate(instance=dictionary,schema=json_schema)

def get_results_from_file(output_location):
    results = []
    with open(output_location) as results_file:
        for x in results_file:
            if len(x.strip()) != 0:
                results.append(json.loads(x))
    return results

def cmp_results(measured, expected, tolerance):
    if measured == expected:
        return True

    assert type(measured) == type(expected), "Type Comparison Mismatch"

    if isinstance(measured, int) or isinstance(measured, float):
        if expected != 0:
            msg = "Measured Value {} not within tolerance ({}) of Expected Value {}"
            assert  (abs(measured-expected) / abs(expected)) < tolerance, \
            msg.format(measured, tolerance, expected)
        else:
            msg = "Measured Value {} not within tolerance ({}) of Expected Value {}"
            assert tolerance > 1, \
            msg.format(measured, tolerance, expected)

        return True

    if isinstance(measured, list):
        print(len(measured))
        print(len(expected))
        assert len(measured) == len(expected), "List length not equal"

        for measured1, expected1 in zip(measured, expected):
            assert cmp_results(measured1, expected1, tolerance), "List items not equal"
        return True

    if isinstance(measured, dict):
        assert len(measured) == len(expected), "Dictionary length not equal"
        for key in measured:
            assert key in expected, "Dictionary keys not equal"
            if key.endswith("id"):
                assert measured[key] == expected[key], "{} doesn't match".format(key)
                return True
            assert cmp_results(measured[key], expected[key], tolerance), "Dictionaries not equal"
        return True

    assert measured == expected, "Values not equal"
    return True

def golden_results(clients, test_case, generate, test_filename):
    results = []
    for client in clients:
        results.extend(get_results_from_file(client.get_output_location()))
    if generate:
        _test_case = copy.deepcopy(test_case)
        _test_case["results"] = results
        with open(test_filename+'.generated', "w") as test_output:
            # Intentionally leave output_location blank so these will be generated by test case handler.
            for client_idx in range(len(clients)):
                _test_case["client"][client_idx]["params"]["output_location"] = ""
            json.dump(_test_case, test_output, indent=4)
    else:
        max_frames = test_case["client"][0]["params"].get("max_frames")
        if max_frames:
            test_case["results"] = test_case["results"][0:max_frames]
        assert cmp_results(results, test_case["results"],
                                    test_case["numerical_tolerance"]), "Inference result mismatch"

def test_rtsp(rtsp_params, frame_destination):
    url = rtsp_params["url"]
    port = rtsp_params["port"]
    if frame_destination.get("type") == "rtsp":
        rtsp_path = frame_destination.get("path")
        rtsp_url = "{}:{}/{}".format(url, port, rtsp_path)
        print("Reading frame from %s", rtsp_url)
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_GSTREAMER)
        ret, frame = cap.read()
        cap.release()
        assert ret, "Unable to read RTSP frame"
        assert frame.size > 0 , "Unable to read RTSP frame"


class ClientProcess:
    def __init__(self, helpers, params, is_concurrent_test):
        self.process = helpers.run_client(params, asynchronous=is_concurrent_test)
        self.helpers = helpers
        self.return_code = params.get("expected_return_code", 0)
        self.output_location = params["output_location"]
        self._wait_to_complete = params.get("wait_to_complete", True)

    def is_running(self):
        return self.process.poll() is None

    def stop(self):
        self.helpers.stop_process(self.process)

    def wait(self):
        if self._wait_to_complete:
            self.process.wait()
        else:
            self.stop()

    def has_correct_return_code(self):
        return self.process.returncode == self.return_code

    def get_output_location(self):
        return self.output_location